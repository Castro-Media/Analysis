{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00052047",
   "metadata": {},
   "source": [
    "# Run Analysis\n",
    "\n",
    "Data sources are stored as arbitrarily deep directories in /data. A data source is a directory with an index file which contains front matter such as filetype, cadence, etc related to how to access the data and when/whether to update the data automatically.  \n",
    "\n",
    "Some data sources have a static cadence, meaning they wont be automatically updated by this notebook.  \n",
    "\n",
    "Others specify an update cadence, a time last updated, and a method of updating which may include things like an api key, etc.  \n",
    "\n",
    "An analysis, likewise will be an arbitrarily deep sirectory wihtin /analysis which contains an index file with front matter like title and dependencies.  \n",
    "\n",
    "Dependencies are paths to data sources or other analyses. Whenever an analysis was last modified before any one of its dependencies, the analysis is stale and needs to be run again.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c687cb04",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T18:56:40.350698Z",
     "iopub.status.busy": "2025-07-23T18:56:40.350495Z",
     "iopub.status.idle": "2025-07-23T18:56:55.847528Z",
     "shell.execute_reply": "2025-07-23T18:56:55.846990Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All dependencies ready.\n"
     ]
    }
   ],
   "source": [
    "#### Make sure all required packages are installed and imported\n",
    "\n",
    "import importlib\n",
    "import subprocess\n",
    "import sys\n",
    "from typing import Optional\n",
    "\n",
    "def _ensure(pkg_name: str, import_name: Optional[str] = None, required: bool = True):\n",
    "    \"\"\"Import a package, installing it if missing.\"\"\"\n",
    "    try:\n",
    "        return importlib.import_module(import_name or pkg_name)\n",
    "    except ModuleNotFoundError:\n",
    "        try:\n",
    "            subprocess.check_call([sys.executable, '-m', 'pip', 'install', pkg_name])\n",
    "        except Exception:\n",
    "            if required:\n",
    "                raise\n",
    "    mod = importlib.import_module(import_name or pkg_name)\n",
    "    globals()[import_name or pkg_name] = mod\n",
    "    return mod\n",
    "\n",
    "_ensure('pandas')\n",
    "_ensure('requests')\n",
    "_ensure('feedparser')\n",
    "_ensure('textblob')\n",
    "_ensure('pyyaml', 'yaml')\n",
    "_ensure('jupyter', required=False)\n",
    "_ensure('nbconvert', required=False)\n",
    "print('All dependencies ready.')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00445370",
   "metadata": {},
   "source": [
    "## Update Data Sources\n",
    "\n",
    "This cell needs to find all of the /data index files, check whether that data source needs to be updated, and then do whatever updates are appropriate.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dcda8f53",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T18:56:55.849489Z",
     "iopub.status.busy": "2025-07-23T18:56:55.849250Z",
     "iopub.status.idle": "2025-07-23T18:58:06.071115Z",
     "shell.execute_reply": "2025-07-23T18:58:06.070560Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Everything up to date.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import datetime as dt\n",
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import json\n",
    "import feedparser\n",
    "import textblob\n",
    "import pandas as pd\n",
    "import requests\n",
    "import urllib.parse\n",
    "import yaml\n",
    "from typing import Optional\n",
    "\n",
    "CADENCE_SECONDS = {\n",
    "    'hourly': 3600,\n",
    "    'daily': 86400,\n",
    "    'weekly': 604800,\n",
    "    'monthly': 2592000,\n",
    "    'quarterly': 7776000,\n",
    "}\n",
    "\n",
    "def substitute_date_tokens(url: str) -> str:\n",
    "    \"\"\"Replace [date %Y-%m-%d] tokens with today's date.\"\"\"\n",
    "    def _replace(m):\n",
    "        return dt.date.today().strftime(m.group(1).strip())\n",
    "    return re.sub(r\"\\[date\\s+([^\\]]+)\\]\", _replace, url)\n",
    "\n",
    "def add_apikey(url: str, env_var: Optional[str]) -> str:\n",
    "    \"\"\"Append an API key from the environment if available.\"\"\"\n",
    "    if env_var:\n",
    "        key = os.getenv(env_var)\n",
    "        if key:\n",
    "            sep = '&' if '?' in url else '?'\n",
    "            return f\"{url}{sep}api_key={urllib.parse.quote_plus(key)}\"\n",
    "    return url\n",
    "\n",
    "def _parse_meta(path: Path):\n",
    "    \"\"\"Return metadata and body text from a markdown file.\"\"\"\n",
    "    text = path.read_text()\n",
    "    m = re.search(r'^---\\n(.*?)\\n---\\n?', text, re.S)\n",
    "    if m:\n",
    "        try:\n",
    "            meta = yaml.safe_load(m.group(1)) or {}\n",
    "        except Exception as e:\n",
    "            print(f'Error parsing metadata in {path}:', e)\n",
    "            raise\n",
    "        body = text[m.end():]\n",
    "    else:\n",
    "        meta, body = {}, text\n",
    "    return meta, body\n",
    "\n",
    "def _write_meta(path: Path, meta: dict, body: str):\n",
    "    \"\"\"Write metadata and body back to a markdown file.\"\"\"\n",
    "    header = yaml.safe_dump(meta, sort_keys=False).strip()\n",
    "    path.write_text(f\"---\\n{header}\\n---\\n{body}\")\n",
    "\n",
    "def _read_index(idx_file: Path):\n",
    "    meta, body = _parse_meta(idx_file)\n",
    "    url = str(meta.get('url', '')).strip()\n",
    "    if not url or url.lower() in ('n/a', 'na', 'none'):\n",
    "        return None\n",
    "    filetype = str(meta.get('filetype', '')).strip().lstrip('.')\n",
    "    cadence = str(meta.get('cadence', 'monthly')).lower()\n",
    "    api_key = meta.get('api_key')\n",
    "    last_fetch = (\n",
    "        pd.to_datetime(meta.get('last_fetched'))\n",
    "        if meta.get('last_fetched') else None\n",
    "    )\n",
    "    return meta, body, url, filetype, cadence, api_key, last_fetch\n",
    "\n",
    "def _build_paths(idx_file: Path, filetype: str, cadence: str,\n",
    "                 now: dt.datetime, today: dt.date):\n",
    "    folder = idx_file.parent\n",
    "    output_ext = 'json' if filetype in ('rss', 'xml') else filetype\n",
    "    latest_fp = folder / f'latest.{output_ext}'\n",
    "    name = f\"{now:%Y-%m-%d-%H}\" if cadence == 'hourly' else f\"{today:%Y-%m-%d}\"\n",
    "    dated_fp = folder / f'{name}.{output_ext}'\n",
    "    return folder, latest_fp, dated_fp\n",
    "\n",
    "def _should_skip(latest_fp: Path, dated_fp: Path,\n",
    "                 last_fetch, now: dt.datetime, min_age: int) -> bool:\n",
    "    if latest_fp.exists() and last_fetch and (now - last_fetch).total_seconds() < min_age:\n",
    "        if dated_fp.exists() and latest_fp.read_bytes() != dated_fp.read_bytes():\n",
    "            shutil.copyfile(dated_fp, latest_fp)\n",
    "        return True\n",
    "    return False\n",
    "\n",
    "def _fetch_content(req_url: str, filetype: str) -> bytes:\n",
    "    \"\"\"Return bytes from a URL or an empty result on error.\"\"\"\n",
    "    try:\n",
    "        resp = requests.get(\n",
    "            req_url,\n",
    "            timeout=30,\n",
    "            headers={'User-Agent': 'Mozilla/5.0'},\n",
    "        )\n",
    "        resp.raise_for_status()\n",
    "    except requests.RequestException as exc:\n",
    "        print(f\"Request failed for {req_url}: {exc}\")\n",
    "        return b''\n",
    "    if filetype in ('rss', 'xml'):\n",
    "        feed = feedparser.parse(resp.content)\n",
    "        entries = []\n",
    "        for entry in feed.entries:\n",
    "            text = ' '.join(\n",
    "                filter(None, [entry.get('title'), entry.get('summary')])\n",
    "            )\n",
    "            pol = textblob.TextBlob(text).sentiment.polarity\n",
    "            entries.append(\n",
    "                {\n",
    "                    'title': entry.get('title'),\n",
    "                    'link': entry.get('link'),\n",
    "                    'published': entry.get('published'),\n",
    "                    'sentiment': pol,\n",
    "                }\n",
    "            )\n",
    "        json_bytes = json.dumps({'entries': entries}, ensure_ascii=False, indent=2).encode('utf-8')\n",
    "        return json_bytes\n",
    "    return resp.content\n",
    "\n",
    "def _write_files(content: bytes, dated_fp: Path, latest_fp: Path):\n",
    "    dated_fp.write_bytes(content)\n",
    "    shutil.copyfile(dated_fp, latest_fp)\n",
    "\n",
    "def _process_index(idx_file: Path, base: Path,\n",
    "                   now: dt.datetime, today: dt.date) -> str | None:\n",
    "    result = _read_index(idx_file)\n",
    "    if not result:\n",
    "        return None\n",
    "    meta, body, url, filetype, cadence, api_key, last_fetch = result\n",
    "    min_age = CADENCE_SECONDS.get(cadence, 2592000)\n",
    "    folder, latest_fp, dated_fp = _build_paths(idx_file, filetype, cadence, now, today)\n",
    "    if _should_skip(latest_fp, dated_fp, last_fetch, now, min_age):\n",
    "        return None\n",
    "    req_url = add_apikey(substitute_date_tokens(url), api_key)\n",
    "    content = _fetch_content(req_url, filetype)\n",
    "    _write_files(content, dated_fp, latest_fp)\n",
    "    meta['last_fetched'] = now.isoformat(timespec='minutes')\n",
    "    _write_meta(idx_file, meta, body)\n",
    "    return str(folder.relative_to(base))\n",
    "\n",
    "def updateData(path: str):\n",
    "    \"\"\"Refresh any outdated data sources.\"\"\"\n",
    "    base = Path(path)\n",
    "    now = dt.datetime.now()\n",
    "    today = now.date()\n",
    "    updated = []\n",
    "    for idx_file in base.rglob('index.md'):\n",
    "        changed = _process_index(idx_file, base, now, today)\n",
    "        if changed:\n",
    "            updated.append(changed)\n",
    "    if updated:\n",
    "        print('Updated:', ', '.join(updated))\n",
    "    else:\n",
    "        print('Everything up to date.')\n",
    "\n",
    "updateData('./data')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc361023",
   "metadata": {},
   "source": [
    "## Update Analyses\n",
    "\n",
    "This cell needs to do the same type of scan across all the analyses in /analysis. It needs to iterate across all the analyses and check the time last modified for all the dependencies. If any dependency was modified more recently than the analysis, then the analysis needs to be run again. The time last modified of the analysis is the most recent file modification time in the analysis directory, because the analysis directory will contain some arbitrary number of output files.  \n",
    "\n",
    "Because some analyses will list other analyses as dependencies, this loop of checking across all of the analyses needs to keep running until none of them have anything to do, up to some reasonable limit of times to prevent arbitrary recursion.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a5b77f2a",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-07-23T18:58:06.072973Z",
     "iopub.status.busy": "2025-07-23T18:58:06.072781Z",
     "iopub.status.idle": "2025-07-23T18:58:40.369820Z",
     "shell.execute_reply": "2025-07-23T18:58:40.369200Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 79\u001b[39m\n\u001b[32m     76\u001b[39m         \u001b[38;5;28;01mfor\u001b[39;00m nb \u001b[38;5;129;01min\u001b[39;00m outdated_nbs:\n\u001b[32m     77\u001b[39m             execute(nb)\n\u001b[32m---> \u001b[39m\u001b[32m79\u001b[39m \u001b[43mupdateAnalyses\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m./analysis\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 77\u001b[39m, in \u001b[36mupdateAnalyses\u001b[39m\u001b[34m(path)\u001b[39m\n\u001b[32m     75\u001b[39m     \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m     76\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m nb \u001b[38;5;129;01min\u001b[39;00m outdated_nbs:\n\u001b[32m---> \u001b[39m\u001b[32m77\u001b[39m     \u001b[43mexecute\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnb\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[5]\u001b[39m\u001b[32m, line 57\u001b[39m, in \u001b[36mexecute\u001b[39m\u001b[34m(nb)\u001b[39m\n\u001b[32m     51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m     52\u001b[39m cmd = [\n\u001b[32m     53\u001b[39m     sys.executable, \u001b[33m'\u001b[39m\u001b[33m-m\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mjupyter\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnbconvert\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     54\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m--to\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33mnotebook\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m--inplace\u001b[39m\u001b[33m'\u001b[39m, \u001b[33m'\u001b[39m\u001b[33m--execute\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m     55\u001b[39m     \u001b[33m'\u001b[39m\u001b[33m--ExecutePreprocessor.timeout=600\u001b[39m\u001b[33m'\u001b[39m, \u001b[38;5;28mstr\u001b[39m(nb),\n\u001b[32m     56\u001b[39m ]\n\u001b[32m---> \u001b[39m\u001b[32m57\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcmd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheck\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:550\u001b[39m, in \u001b[36mrun\u001b[39m\u001b[34m(input, capture_output, timeout, check, *popenargs, **kwargs)\u001b[39m\n\u001b[32m    548\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m Popen(*popenargs, **kwargs) \u001b[38;5;28;01mas\u001b[39;00m process:\n\u001b[32m    549\u001b[39m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m550\u001b[39m         stdout, stderr = \u001b[43mprocess\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    551\u001b[39m     \u001b[38;5;28;01mexcept\u001b[39;00m TimeoutExpired \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    552\u001b[39m         process.kill()\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1201\u001b[39m, in \u001b[36mPopen.communicate\u001b[39m\u001b[34m(self, input, timeout)\u001b[39m\n\u001b[32m   1199\u001b[39m         stderr = \u001b[38;5;28mself\u001b[39m.stderr.read()\n\u001b[32m   1200\u001b[39m         \u001b[38;5;28mself\u001b[39m.stderr.close()\n\u001b[32m-> \u001b[39m\u001b[32m1201\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1202\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1203\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1264\u001b[39m, in \u001b[36mPopen.wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1262\u001b[39m     endtime = _time() + timeout\n\u001b[32m   1263\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1264\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1265\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[32m   1266\u001b[39m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[32m   1267\u001b[39m     \u001b[38;5;66;03m# The first keyboard interrupt waits briefly for the child to\u001b[39;00m\n\u001b[32m   1268\u001b[39m     \u001b[38;5;66;03m# exit under the common assumption that it also received the ^C\u001b[39;00m\n\u001b[32m   1269\u001b[39m     \u001b[38;5;66;03m# generated SIGINT and will exit rapidly.\u001b[39;00m\n\u001b[32m   1270\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32mC:\\Program Files\\WindowsApps\\PythonSoftwareFoundation.Python.3.11_3.11.2544.0_x64__qbz5n2kfra8p0\\Lib\\subprocess.py:1590\u001b[39m, in \u001b[36mPopen._wait\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1587\u001b[39m     timeout_millis = \u001b[38;5;28mint\u001b[39m(timeout * \u001b[32m1000\u001b[39m)\n\u001b[32m   1588\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.returncode \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m   1589\u001b[39m     \u001b[38;5;66;03m# API note: Returns immediately if timeout_millis == 0.\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1590\u001b[39m     result = _winapi.WaitForSingleObject(\u001b[38;5;28mself\u001b[39m._handle,\n\u001b[32m   1591\u001b[39m                                          timeout_millis)\n\u001b[32m   1592\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m result == _winapi.WAIT_TIMEOUT:\n\u001b[32m   1593\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m TimeoutExpired(\u001b[38;5;28mself\u001b[39m.args, timeout)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "import re\n",
    "import subprocess\n",
    "import sys\n",
    "import yaml\n",
    "from typing import List\n",
    "\n",
    "def _parse_meta(path: Path):\n",
    "    \"\"\"Return metadata and body from a markdown file.\"\"\"\n",
    "    text = path.read_text()\n",
    "    m = re.search(r'^---\\n(.*?)\\n---\\n?', text, re.S)\n",
    "    if m:\n",
    "        try:\n",
    "            meta = yaml.safe_load(m.group(1)) or {}\n",
    "        except Exception as e:\n",
    "            print(f'Error parsing metadata in {path}:', e)\n",
    "            raise\n",
    "        body = text[m.end():]\n",
    "    else:\n",
    "        meta, body = {}, text\n",
    "    return meta, body\n",
    "\n",
    "def _latest_mtime(p: Path) -> float:\n",
    "    \"\"\"Return the most recent modification time in a path.\"\"\"\n",
    "    if p.is_file():\n",
    "        return p.stat().st_mtime\n",
    "    mt = [f.stat().st_mtime for f in p.rglob('*') if f.is_file()]\n",
    "    return max(mt) if mt else p.stat().st_mtime\n",
    "\n",
    "def build_dep_map(analysis_dir: Path, repo_dir: Path):\n",
    "    \"\"\"Map notebooks to their dependency paths.\"\"\"\n",
    "    dep_map = {}\n",
    "    for meta in analysis_dir.rglob('index.md'):\n",
    "        info, _ = _parse_meta(meta)\n",
    "        deps = [(repo_dir / d).resolve() for d in info.get('dependencies', [])]\n",
    "        for nb in meta.parent.glob('*.ipynb'):\n",
    "            dep_map[nb] = deps\n",
    "    return dep_map\n",
    "\n",
    "def outdated(nb: Path, deps: List[Path]) -> bool:\n",
    "    \"\"\"Return True if any dependency is newer than the notebook.\"\"\"\n",
    "    nb_m = _latest_mtime(nb)\n",
    "    return any(_latest_mtime(d) > nb_m for d in deps)\n",
    "\n",
    "def execute(nb: Path):\n",
    "    \"\"\"Run a notebook in-place if jupyter is available.\"\"\"\n",
    "    import shutil\n",
    "    if not shutil.which('jupyter'):\n",
    "        print('jupyter not available - skipping', nb)\n",
    "        return\n",
    "    cmd = [\n",
    "        sys.executable, '-m', 'jupyter', 'nbconvert',\n",
    "        '--to', 'notebook', '--inplace', '--execute',\n",
    "        '--ExecutePreprocessor.timeout=600', str(nb),\n",
    "    ]\n",
    "    subprocess.run(cmd, check=False)\n",
    "\n",
    "def updateAnalyses(path: str):\n",
    "    \"\"\"Execute notebooks whose dependencies have changed.\"\"\"\n",
    "    repo_dir = Path('.').resolve()\n",
    "    analysis_dir = repo_dir / path\n",
    "    for _ in range(10):\n",
    "        dep_map = build_dep_map(analysis_dir, repo_dir)\n",
    "        outdated_nbs = [\n",
    "            nb for nb, deps in dep_map.items() if deps and outdated(nb, deps)\n",
    "        ]\n",
    "        json.dump(\n",
    "            {'outdated_notebooks': [str(nb) for nb in outdated_nbs]},\n",
    "            open('dependencies.json', 'w'),\n",
    "            indent=2,\n",
    "        )\n",
    "        if not outdated_nbs:\n",
    "            print('Everything up to date.')\n",
    "            break\n",
    "        for nb in outdated_nbs:\n",
    "            execute(nb)\n",
    "\n",
    "updateAnalyses('./analysis')\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
