---
layout: default
title: Amazon
name: Amazon
category: corporation
compute: 5e+19
stakeholders: 15
---

## Description
Amazon operates Amazon Web Services (AWS), a cloud platform that supplies GPU resources for internal and customer AI workloads.

## Scope
- Reports indicate AWS procured around 50,000 NVIDIA H100 GPUs, providing roughly 5×10^19 dense INT8 operations per second.[^1][^2]
- Older-generation accelerators across AWS regions contribute additional capacity.

Total compute: about 5×10^19 dense INT8 operations per second.

## Implications
Amazon's control over AWS concentrates a large share of global AI compute in one corporation, shaping who can access high-end hardware and at what terms.

## Works cited
[^1]: Observer, "Amazon Orders 50,000 H100 GPUs for AWS," 2023. <https://observer.com/amazon-50000-h100-gpus/>
[^2]: Colfax, "NVIDIA H100 Tensor Core GPU," 2023. <https://colfaxresearch.com/nvidia-h100-performance/>
