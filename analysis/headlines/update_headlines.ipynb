{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Update Headlines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import csv\n",
    "import json\n",
    "import xml.etree.ElementTree as ET\n",
    "from datetime import datetime\n",
    "import shutil\n",
    "\n",
    "DATA_DIR = Path('data').resolve()\n",
    "HEADLINES_DIR = Path('analysis/headlines').resolve()\n",
    "HEADLINES_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "def parse_feed(path: Path):\n",
    "    entries = []\n",
    "    if path.suffix == '.json':\n",
    "        with open(path, 'r', encoding='utf-8') as f:\n",
    "            data = json.load(f)\n",
    "        for item in data.get('entries', []):\n",
    "            title = item.get('title')\n",
    "            link = item.get('link')\n",
    "            if title and link:\n",
    "                entries.append((title.strip(), link.strip()))\n",
    "    else:\n",
    "        try:\n",
    "            tree = ET.parse(path)\n",
    "            root = tree.getroot()\n",
    "        except ET.ParseError:\n",
    "            return entries\n",
    "        for item in root.iter():\n",
    "            if item.tag.lower().endswith(('item', 'entry')):\n",
    "                title = None\n",
    "                link = None\n",
    "                for child in item:\n",
    "                    if child.tag.lower().endswith('title'):\n",
    "                        title = (child.text or '').strip()\n",
    "                    if child.tag.lower().endswith('link'):\n",
    "                        link = (child.text or '').strip() or child.attrib.get('href')\n",
    "                if title and link:\n",
    "                    entries.append((title, link))\n",
    "    return entries\n",
    "\n",
    "def collect_headlines():\n",
    "    all_entries = []\n",
    "    for source in DATA_DIR.iterdir():\n",
    "        if source.is_dir() and source.name.startswith('news'):\n",
    "            candidates = [p for p in source.rglob('latest.*') if p.suffix in {'.json', '.rss', '.xml'}]\n",
    "            if not candidates:\n",
    "                candidates = [p for p in source.rglob('*') if p.suffix in {'.json', '.rss', '.xml'}]\n",
    "            if not candidates:\n",
    "                continue\n",
    "            latest_file = max(candidates, key=lambda p: p.stat().st_mtime)\n",
    "            all_entries.extend(parse_feed(latest_file))\n",
    "    return all_entries\n",
    "\n",
    "def update_headlines():\n",
    "    timestamp = datetime.utcnow().strftime('%Y-%m-%d-%H-00')\n",
    "    hourly_file = HEADLINES_DIR / f'{timestamp}.csv'\n",
    "    if hourly_file.exists():\n",
    "        print(f'{hourly_file.name} already exists. Skipping update.')\n",
    "        return\n",
    "    entries = collect_headlines()\n",
    "    with open(hourly_file, 'w', newline='', encoding='utf-8') as f:\n",
    "        writer = csv.writer(f)\n",
    "        writer.writerow(['title', 'link'])\n",
    "        writer.writerows(entries)\n",
    "    latest_file = HEADLINES_DIR / 'latest.csv'\n",
    "    shutil.copy(hourly_file, latest_file)\n",
    "    print(f'Wrote {hourly_file} and updated latest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\CJ\\AppData\\Local\\Temp\\ipykernel_36192\\1769414990.py:55: DeprecationWarning: datetime.datetime.utcnow() is deprecated and scheduled for removal in a future version. Use timezone-aware objects to represent datetimes in UTC: datetime.datetime.now(datetime.UTC).\n",
      "  timestamp = datetime.utcnow().strftime('%Y-%m-%d-%H-00')\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\CJ\\\\Documents\\\\GitHub\\\\Analysis\\\\analysis\\\\headlines\\\\data'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mupdate_headlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 60\u001b[39m, in \u001b[36mupdate_headlines\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mhourly_file.name\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m already exists. Skipping update.\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     59\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m60\u001b[39m entries = \u001b[43mcollect_headlines\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     61\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(hourly_file, \u001b[33m'\u001b[39m\u001b[33mw\u001b[39m\u001b[33m'\u001b[39m, newline=\u001b[33m'\u001b[39m\u001b[33m'\u001b[39m, encoding=\u001b[33m'\u001b[39m\u001b[33mutf-8\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m     62\u001b[39m     writer = csv.writer(f)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 43\u001b[39m, in \u001b[36mcollect_headlines\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m     41\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mcollect_headlines\u001b[39m():\n\u001b[32m     42\u001b[39m     all_entries = []\n\u001b[32m---> \u001b[39m\u001b[32m43\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mDATA_DIR\u001b[49m\u001b[43m.\u001b[49m\u001b[43miterdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     44\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mis_dir\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mname\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstartswith\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnews\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     45\u001b[39m \u001b[43m            \u001b[49m\u001b[43mcandidates\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msource\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrglob\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mlatest.*\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mp\u001b[49m\u001b[43m.\u001b[49m\u001b[43msuffix\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.json\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.rss\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43m.xml\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m}\u001b[49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\Users\\CJ\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\pathlib.py:1057\u001b[39m, in \u001b[36mPath.iterdir\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1051\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34miterdir\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1052\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"Yield path objects of the directory contents.\u001b[39;00m\n\u001b[32m   1053\u001b[39m \n\u001b[32m   1054\u001b[39m \u001b[33;03m    The children are yielded in arbitrary order, and the\u001b[39;00m\n\u001b[32m   1055\u001b[39m \u001b[33;03m    special entries '.' and '..' are not included.\u001b[39;00m\n\u001b[32m   1056\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1057\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[43mos\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlistdir\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[32m   1058\u001b[39m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[38;5;28mself\u001b[39m._make_child_relpath(name)\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [WinError 3] The system cannot find the path specified: 'C:\\\\Users\\\\CJ\\\\Documents\\\\GitHub\\\\Analysis\\\\analysis\\\\headlines\\\\data'"
     ]
    }
   ],
   "source": [
    "update_headlines()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
